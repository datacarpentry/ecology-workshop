---
layout: lesson
root: .
---

Data Carpentry's aim is to teach researchers basic concepts, skills, and tools for working with data so that they can get more done in less time, and with less pain. This workshop uses a tabular ecology dataset and teaches data cleaning, management, analysis and visualization. 


> ## Prerequisites
>
> There are no pre-requisites, and the materials assume no prior knowledge about the tools.
{: .prereq}

> ## Data
> 
> The data for this workshop are is the [Portal Project Teaching Database](https://figshare.com/articles/Portal_Project_Teaching_Database/1314459) available on FigShare, with a CC-BY license available for reuse.
>
> The Portal Project Teaching Database is a simplified version of the Portal 
> Project Database designed for teaching. It is a tabular dataset of observations
> of small mammals in a desert ecosystem in Arizona, USA, collected over more than 40 years.
> It provides a real world example of 
> life-history, population, and ecological data, with sufficient complexity to 
> teach many aspects of data analysis and management, but with many complexities
> removed to allow students to focus on the core ideas and skills being taught.
>
> [More information on this dataset](data)
{: .prereq}

The workshop can be taught using R or Python as the base language.

Overview of the lessons:

  * Data organization in spreadsheets
  * Data cleaning with OpenRefine
  * Introduction to R or python
  * Data analysis and visualization in R or python
  * SQL for data management

## Detailed structure

### Day 1 morning: Data organization & cleaning

There are two lessons in this section. The first is a spreadsheet lesson that teaches  good data organization, and some data cleaning and quality control checking in a spreadsheet program.

  * [spreadsheet lesson](http://www.datacarpentry.org/spreadsheet-ecology-lesson/)
  * [spreadsheet repository](https://github.com/datacarpentry/spreadsheet-ecology-lesson)

The second lesson uses a program called [OpenRefine](http://openrefine.org/) to teach data cleaning and filtering, and to introduce the idea scripting (application programming interfaces).

  * [OpenRefine lesson](http://www.datacarpentry.org/OpenRefine-ecology-lesson/)
  * [OpenRefine repository](https://github.com/datacarpentry/OpenRefine-ecology-lesson)

### Day 1 afternoon and Day 2 morning: Data analysis & visualization

These lessons include:

* a basic information to R or Python syntax
* importing CSV data
* subsetting and merging data
* how to do plotting

Lessons:

  * [R lesson](http://www.datacarpentry.org/R-ecology-lesson/) and [python lesson](http://www.datacarpentry.org/python-ecology-lesson/)
  * [R repository](https://github.com/datacarpentry/R-ecology-lesson) and [python repository](https://github.com/datacarpentry/python-ecology-lesson)


### Day 2 afternoon: Data management with SQL

This lesson introduces the concept of a database using SQLite, how to structure data for easy database import, and how to import tabular data into SQLite. Then, it teaches basic queries, combining results and doing queries across multiple tables.  

  * [SQL lesson](http://www.datacarpentry.org/sql-ecology-lesson/)
  * [SQL repository](https://github.com/datacarpentry/sql-ecology-lesson)

## Other lessons

There are a number of other ecology lessons that are not part of the base workshop. Some of these are no longer taught, and some are only taught at extended workshops.

  * [shell-ecology](https://github.com/datacarpentry/shell-ecology)

